{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOjvNZN88QQcRDttvmEDw/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"n3B1ptRfjwPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701555565775,"user_tz":180,"elapsed":762,"user":{"displayName":"ALONDRA LORETO ARAYA","userId":"02173873226829090470"}},"outputId":"38090fde-dd18-4b90-9560-11f7b95c36c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing collected packages: typeguard, tensorflow-addons, keras-applications, image-classifiers, flammkuchen, efficientnet, segmentation-models\n","Successfully installed efficientnet-1.0.0 flammkuchen-1.0.3 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1 tensorflow-addons-0.23.0 typeguard-2.13.3\n"]}],"source":["!pip install tensorflow numpy pandas tqdm scikit-learn segmentation-models tensorflow-addons flammkuchen opencv-python-headless imageio"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIMN_APJj2UW","executionInfo":{"status":"ok","timestamp":1701555586391,"user_tz":180,"elapsed":20620,"user":{"displayName":"ALONDRA LORETO ARAYA","userId":"02173873226829090470"}},"outputId":"d0f782c9-4434-4419-95b4-3b6cc55656d0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import tensorflow as tf\n","os.environ['SM_FRAMEWORK'] = 'tf.keras'\n","import numpy as np\n","import pandas as pd\n","import random\n","from tqdm.notebook import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","from segmentation_models.losses import dice_loss\n","from segmentation_models.metrics import iou_score\n","\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.data import load_data, metric_mape, mape_ap, mape_pp\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Utils.Callbacks import get_callbacks\n","from drive.MyDrive.Glottis.colab_glottis.GlottisNetV2.Models.GlottisNetV2_e import glottisnetV2_e\n","\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1B60TXUj5Fp","executionInfo":{"status":"ok","timestamp":1701555595983,"user_tz":180,"elapsed":9594,"user":{"displayName":"ALONDRA LORETO ARAYA","userId":"02173873226829090470"}},"outputId":"6e3e20f0-24a9-48b6-f28b-1ec90ecbc296"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Segmentation Models: using `tf.keras` framework.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import cv2\n","import imageio as io\n","from tensorflow.keras.models import load_model\n","import flammkuchen as fl\n","from google.colab.patches import cv2_imshow\n","import tensorflow_addons as tfa\n","\n","def extract_points_from_heatmap(heatmap):\n","    points = []\n","    for i in range(heatmap.shape[-1]):  #\n","        y, x = np.unravel_index(np.argmax(heatmap[..., i]), heatmap[..., i].shape)\n","        points.append((x, y))\n","    return points[0], points[1]\n","\n","def draw_points_and_line(img, point1, point2, color_points=(0, 255, 255), color_line=(0, 255, 255), thickness=2):\n","    cv2.circle(img, point1, radius=5, color=color_points, thickness=-1)\n","    cv2.circle(img, point2, radius=5, color=color_points, thickness=-1)\n","    cv2.line(img, point1, point2, color=color_line, thickness=thickness)\n","    return img\n","\n","def draw_contours_on_image(mask, img, contour_color=(255, 0, 0)):\n","    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    cv2.drawContours(img, contours, -1, contour_color, 2)\n","    return img"],"metadata":{"id":"sXMSAAQTNo5_","executionInfo":{"status":"ok","timestamp":1701555653002,"user_tz":180,"elapsed":334,"user":{"displayName":"ALONDRA LORETO ARAYA","userId":"02173873226829090470"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def process_and_recreate_video(video_path, model_path, output_video_path):\n","    model = load_model(model_path, compile=False)\n","\n","    # Leer el video y preparar la escritura del video de salida\n","    ims = io.mimread(video_path, memtest=False)\n","    cap = cv2.VideoCapture(video_path)\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (ims[0].shape[1], ims[0].shape[0]))\n","\n","    # Procesar cada frame del video\n","    for i in range(len(ims)):\n","        img_original = ims[i].astype(np.float32)\n","        img_original = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img_original, (256, 512))\n","\n","        # Normalizar y preprocesar la imagen\n","        normalizedImg = np.zeros(img.shape)\n","        img = cv2.normalize(img, normalizedImg, -1, 1, cv2.NORM_MINMAX)\n","        img = img[None, ..., None]\n","\n","        # Prediccion\n","        points_pred, seg_pred = model.predict(img)\n","        mask = np.asarray(np.squeeze(seg_pred))\n","        points_pred = np.asarray(np.squeeze(points_pred))\n","\n","        point1, point2 = extract_points_from_heatmap(points_pred)\n","\n","        # Convertir la máscara de segmentación predicha a binaria y dibujar los contornos\n","        mask = np.round(mask)\n","        mask = cv2.resize(mask, (img_original.shape[1], img_original.shape[0]))\n","        mask = mask.astype(bool)\n","        img_with_contours = draw_contours_on_image(mask.astype(np.uint8), ims[i], contour_color=(255, 0, 0))\n","\n","        # Dibujar los puntos y la línea en la imagen\n","        img_with_points_and_line = draw_points_and_line(img_with_contours, point1, point2)\n","\n","        # Escribir el frame procesado en el video de salida\n","        video_writer.write(img_with_points_and_line.astype(np.uint8))\n","\n","    # Liberar los recursos de VideoWriter y VideoCapture\n","    video_writer.release()\n","    cap.release()\n"],"metadata":{"id":"JfD0clYSig7F","executionInfo":{"status":"ok","timestamp":1701556399828,"user_tz":180,"elapsed":351,"user":{"displayName":"ALONDRA LORETO ARAYA","userId":"02173873226829090470"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model_path = 'drive/MyDrive/Glottis/GlottisNetV2e/models/steps/epoch025.h5'\n","video_path = 'drive/MyDrive/Glottis/videos_BAGLS/100.mp4'\n","output_video_path = '/content/drive/MyDrive/Glottis/videos_segmentados/100_v2.mp4'\n","process_and_recreate_video(video_path, model_path, output_video_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INPnN6ZRmpf2","executionInfo":{"status":"ok","timestamp":1701556429780,"user_tz":180,"elapsed":28046,"user":{"displayName":"ALONDRA LORETO ARAYA","userId":"02173873226829090470"}},"outputId":"e1936061-9d49-446f-b887-141e11c0276e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n","WARNING:root:The given value for groups will be overwritten.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 1s 886ms/step\n","1/1 [==============================] - 1s 773ms/step\n","1/1 [==============================] - 1s 736ms/step\n","1/1 [==============================] - 0s 477ms/step\n","1/1 [==============================] - 0s 486ms/step\n","1/1 [==============================] - 0s 490ms/step\n","1/1 [==============================] - 0s 480ms/step\n","1/1 [==============================] - 0s 481ms/step\n","1/1 [==============================] - 0s 498ms/step\n","1/1 [==============================] - 0s 476ms/step\n","1/1 [==============================] - 0s 478ms/step\n","1/1 [==============================] - 0s 470ms/step\n","1/1 [==============================] - 0s 471ms/step\n","1/1 [==============================] - 0s 471ms/step\n","1/1 [==============================] - 0s 463ms/step\n","1/1 [==============================] - 0s 485ms/step\n","1/1 [==============================] - 0s 480ms/step\n","1/1 [==============================] - 0s 481ms/step\n","1/1 [==============================] - 1s 633ms/step\n","1/1 [==============================] - 1s 890ms/step\n","1/1 [==============================] - 1s 842ms/step\n","1/1 [==============================] - 1s 792ms/step\n","1/1 [==============================] - 1s 884ms/step\n","1/1 [==============================] - 1s 835ms/step\n","1/1 [==============================] - 1s 787ms/step\n","1/1 [==============================] - 1s 689ms/step\n","1/1 [==============================] - 0s 484ms/step\n","1/1 [==============================] - 0s 463ms/step\n","1/1 [==============================] - 0s 473ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gVlGZdOFcp2Y"},"execution_count":null,"outputs":[]}]}